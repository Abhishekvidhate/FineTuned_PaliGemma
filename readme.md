# Fine Tuning Multi-Modal Language Model ( VLM )

for this assignment I selected **Pali Gemma** model to work on. Pali Gemma is an advanced open-source vision-language model by Google Research, designed for tasks like image captioning and visual question answering.


### I selected **Pali Gemma** because of it's **Architecture**, [learn more](https://huggingface.co/blog/paligemma)

![image](https://github.com/Abhishekvidhate/FineTuned_PaliGemma/assets/120262589/8bf94eda-6f61-42d6-8cb3-0626f5c8d275)

### I wanted to Fine tune a model on Different techinque other than LORA and QLORA, so i think **Pali Gemma** would be best fit for this.

