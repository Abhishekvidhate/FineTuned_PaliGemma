{
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "accelerator": "GPU",
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 8874883,
     "sourceType": "datasetVersion",
     "datasetId": 5342204
    }
   ],
   "dockerImageVersionId": 30733,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "!pip install -q -U git+https://github.com/huggingface/transformers.git\n!pip install -q -U datasets accelerate\n!pip install -q -U accelerate\n!pip install -q -U peft\n!pip install -q -U bitsandbytes",
   "metadata": {
    "id": "xVYYCj9i2wq3",
    "execution": {
     "iopub.status.busy": "2024-07-05T23:44:58.260967Z",
     "iopub.execute_input": "2024-07-05T23:44:58.261602Z",
     "iopub.status.idle": "2024-07-05T23:46:59.248694Z",
     "shell.execute_reply.started": "2024-07-05T23:44:58.261565Z",
     "shell.execute_reply": "2024-07-05T23:46:59.247469Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# load Dataset\n\nI already downloaded DocVQA (60+ GB) , processed data ( made it PaliGemma input ready ; removed unnecessary columns )",
   "metadata": {
    "id": "Ef-SRBmX24PK"
   }
  },
  {
   "cell_type": "markdown",
   "source": "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",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Entry your HF_TOKEN (write permission token only) to authenticate\n\nfrom huggingface_hub import notebook_login\nnotebook_login()",
   "metadata": {
    "id": "9V355UVr3QdF",
    "execution": {
     "iopub.status.busy": "2024-07-05T23:46:59.250927Z",
     "iopub.execute_input": "2024-07-05T23:46:59.251630Z",
     "iopub.status.idle": "2024-07-05T23:46:59.541623Z",
     "shell.execute_reply.started": "2024-07-05T23:46:59.251589Z",
     "shell.execute_reply": "2024-07-05T23:46:59.540732Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from datasets import load_dataset\n\ntrain_ds = load_dataset(\"abhishekvidhate/DocQVA_small\")",
   "metadata": {
    "id": "tC-HO1kW3sw5",
    "execution": {
     "iopub.status.busy": "2024-07-05T23:47:38.456226Z",
     "iopub.execute_input": "2024-07-05T23:47:38.456633Z",
     "iopub.status.idle": "2024-07-05T23:47:43.248699Z",
     "shell.execute_reply.started": "2024-07-05T23:47:38.456600Z",
     "shell.execute_reply": "2024-07-05T23:47:43.247896Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_ds",
   "metadata": {
    "id": "Wkl7pOcz3T4O",
    "execution": {
     "iopub.status.busy": "2024-07-05T23:47:43.250548Z",
     "iopub.execute_input": "2024-07-05T23:47:43.251363Z",
     "iopub.status.idle": "2024-07-05T23:47:43.257832Z",
     "shell.execute_reply.started": "2024-07-05T23:47:43.251318Z",
     "shell.execute_reply": "2024-07-05T23:47:43.256899Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_small = train_ds['train_small']",
   "metadata": {
    "id": "abLkRsUy-fvg",
    "execution": {
     "iopub.status.busy": "2024-07-05T23:47:43.259602Z",
     "iopub.execute_input": "2024-07-05T23:47:43.259916Z",
     "iopub.status.idle": "2024-07-05T23:47:43.409409Z",
     "shell.execute_reply.started": "2024-07-05T23:47:43.259892Z",
     "shell.execute_reply": "2024-07-05T23:47:43.408018Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_small",
   "metadata": {
    "id": "YuuCrzk6-mKy",
    "execution": {
     "iopub.status.busy": "2024-07-05T23:47:43.414193Z",
     "iopub.execute_input": "2024-07-05T23:47:43.415664Z",
     "iopub.status.idle": "2024-07-05T23:47:43.422045Z",
     "shell.execute_reply.started": "2024-07-05T23:47:43.415622Z",
     "shell.execute_reply": "2024-07-05T23:47:43.420852Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_small.to_pandas()",
   "metadata": {
    "id": "FO-NL6UT3wr7",
    "execution": {
     "iopub.status.busy": "2024-07-05T23:47:43.423522Z",
     "iopub.execute_input": "2024-07-05T23:47:43.423861Z",
     "iopub.status.idle": "2024-07-05T23:47:43.779233Z",
     "shell.execute_reply.started": "2024-07-05T23:47:43.423829Z",
     "shell.execute_reply": "2024-07-05T23:47:43.778502Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Create Model inputd; process dataset to make it Pali Gemma ready i.e build DataCollator",
   "metadata": {
    "id": "UtVcFo7033dL"
   }
  },
  {
   "cell_type": "code",
   "source": "from transformers import PaliGemmaProcessor\n\nmodel_id = \"google/paligemma-3b-pt-224\"\nprocessor = PaliGemmaProcessor.from_pretrained(model_id)",
   "metadata": {
    "id": "FL-bFd0637LM",
    "execution": {
     "iopub.status.busy": "2024-07-05T23:47:43.780463Z",
     "iopub.execute_input": "2024-07-05T23:47:43.781192Z",
     "iopub.status.idle": "2024-07-05T23:48:04.045395Z",
     "shell.execute_reply.started": "2024-07-05T23:47:43.781154Z",
     "shell.execute_reply": "2024-07-05T23:48:04.044577Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import torch\ndevice = \"cuda\"\n\nimage_token = processor.tokenizer.convert_tokens_to_ids(\"<image>\")\ndef collate_fn(examples):\n  texts = [\"answer \" + example[\"question\"] for example in examples]\n  labels = [\"; \".join(example['answers']) for example in examples]\n  images = [example[\"image\"].convert(\"RGB\") for example in examples]\n  tokens = processor(text=texts, images=images, suffix=labels,\n                    return_tensors=\"pt\", padding=\"longest\",\n                    tokenize_newline_separately=False)\n\n  tokens = tokens.to(device)\n  return tokens",
   "metadata": {
    "id": "XQVxjunY3-ku",
    "execution": {
     "iopub.status.busy": "2024-07-05T23:48:04.046520Z",
     "iopub.execute_input": "2024-07-05T23:48:04.047086Z",
     "iopub.status.idle": "2024-07-05T23:48:04.053598Z",
     "shell.execute_reply.started": "2024-07-05T23:48:04.047059Z",
     "shell.execute_reply": "2024-07-05T23:48:04.052639Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Load Model\n\nI'm using loading model in 4bit configuration , so i can easily do LoRA and QLoRA",
   "metadata": {
    "id": "Lwok670c4Ckl"
   }
  },
  {
   "cell_type": "code",
   "source": "from transformers import BitsAndBytesConfig\nfrom peft import get_peft_model, LoraConfig\nfrom transformers import PaliGemmaForConditionalGeneration\n\nbnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_type=torch.float16\n)\n\nlora_config = LoraConfig(\n    r=4,\n    target_modules=[\"self_attn.out_proj\", \"fc1\", \"fc2\"],  # Targeting linear layers\n#     target_modules=[\"q_proj\", \"k_proj\"]\n#     target_modules=[\"q_proj\", \"v_proj\", \"k_proj\"],\n    task_type=\"CAUSAL_LM\",\n)\nmodel = PaliGemmaForConditionalGeneration.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()",
   "metadata": {
    "id": "n1lGk8oP4BcE",
    "execution": {
     "iopub.status.busy": "2024-07-05T23:48:04.055492Z",
     "iopub.execute_input": "2024-07-05T23:48:04.055782Z",
     "iopub.status.idle": "2024-07-05T23:49:04.456993Z",
     "shell.execute_reply.started": "2024-07-05T23:48:04.055758Z",
     "shell.execute_reply": "2024-07-05T23:49:04.456118Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Training Arguments for fine tuning",
   "metadata": {
    "id": "SZskl6l04Jge"
   }
  },
  {
   "cell_type": "code",
   "source": "from transformers import TrainingArguments\n\nargs=TrainingArguments(\n            num_train_epochs=2,\n            remove_unused_columns=False,\n            per_device_train_batch_size=2,\n            gradient_accumulation_steps=4,\n            warmup_steps=2,\n            learning_rate=2e-5,\n            weight_decay=1e-6,\n            adam_beta2=0.999,\n            logging_steps=100,\n            optim=\"adamw_hf\",\n            save_strategy=\"steps\",\n            save_steps=500,\n            push_to_hub=True,\n            save_total_limit=1,\n            output_dir=\"Abhishek-PaliGemma-FT\",\n            dataloader_pin_memory=False,\n            report_to=[]  # Disable Wandb integration, no tracing to wandb\n        )",
   "metadata": {
    "id": "fYloLoYo4L3C",
    "execution": {
     "iopub.status.busy": "2024-07-06T00:02:04.598938Z",
     "iopub.execute_input": "2024-07-06T00:02:04.599306Z",
     "iopub.status.idle": "2024-07-06T00:02:04.633336Z",
     "shell.execute_reply.started": "2024-07-06T00:02:04.599274Z",
     "shell.execute_reply": "2024-07-06T00:02:04.632587Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from transformers import Trainer\n\ntrainer = Trainer(\n        model=model,\n        train_dataset=train_small ,\n        data_collator=collate_fn,\n        args=args\n        )",
   "metadata": {
    "id": "9Dlw68It4Tlm",
    "execution": {
     "iopub.status.busy": "2024-07-06T00:02:11.268296Z",
     "iopub.execute_input": "2024-07-06T00:02:11.269098Z",
     "iopub.status.idle": "2024-07-06T00:02:11.538048Z",
     "shell.execute_reply.started": "2024-07-06T00:02:11.269066Z",
     "shell.execute_reply": "2024-07-06T00:02:11.537246Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "trainer.train()",
   "metadata": {
    "id": "L7cBuMlK4VM_",
    "execution": {
     "iopub.status.busy": "2024-07-06T00:02:15.097319Z",
     "iopub.execute_input": "2024-07-06T00:02:15.098131Z",
     "iopub.status.idle": "2024-07-06T00:05:35.592405Z",
     "shell.execute_reply.started": "2024-07-06T00:02:15.098096Z",
     "shell.execute_reply": "2024-07-06T00:05:35.591422Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Pushing Model to Huggingface for future inference",
   "metadata": {
    "id": "0UBckNim4XG_"
   }
  },
  {
   "cell_type": "code",
   "source": "trainer.push_to_hub()",
   "metadata": {
    "id": "dxMEOzI_4YlY",
    "execution": {
     "iopub.status.busy": "2024-07-06T00:05:46.747020Z",
     "iopub.execute_input": "2024-07-06T00:05:46.747401Z",
     "iopub.status.idle": "2024-07-06T00:05:47.693044Z",
     "shell.execute_reply.started": "2024-07-06T00:05:46.747352Z",
     "shell.execute_reply": "2024-07-06T00:05:47.692134Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Simple Inference of my FinedTuned Pali Gemma\n\nwill build Streamlit App deployed on cloud, so user won't have to run python code again and again, also with secret privacy safe",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n\nmodel_id = \"abhishekvidhate/Abhishek-PaliGemma-FT\"\nmodel = PaliGemmaForConditionalGeneration.from_pretrained(model_id)\nprocessor = AutoProcessor.from_pretrained(\"google/paligemma-3b-pt-224\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T00:18:48.243787Z",
     "iopub.execute_input": "2024-07-06T00:18:48.244149Z",
     "iopub.status.idle": "2024-07-06T00:19:19.590858Z",
     "shell.execute_reply.started": "2024-07-06T00:18:48.244118Z",
     "shell.execute_reply": "2024-07-06T00:19:19.589906Z"
    },
    "trusted": true
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from PIL import Image\nimport requests\n\n\nprompt = \"What is behind the cat?\"\nimage_file = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/cat.png?download=true\"\nraw_image = Image.open(requests.get(image_file, stream=True).raw)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T00:30:37.294127Z",
     "iopub.execute_input": "2024-07-06T00:30:37.294887Z",
     "iopub.status.idle": "2024-07-06T00:30:37.509308Z",
     "shell.execute_reply.started": "2024-07-06T00:30:37.294855Z",
     "shell.execute_reply": "2024-07-06T00:30:37.508557Z"
    },
    "trusted": true
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "inputs = processor(prompt, raw_image.convert(\"RGB\"), return_tensors=\"pt\")\noutput = model.generate(**inputs, max_new_tokens=20)\n\nprint(processor.decode(output[0], skip_special_tokens=True)[len(prompt):])\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T00:31:31.971082Z",
     "iopub.execute_input": "2024-07-06T00:31:31.971438Z",
     "iopub.status.idle": "2024-07-06T00:31:40.479228Z",
     "shell.execute_reply.started": "2024-07-06T00:31:31.971410Z",
     "shell.execute_reply": "2024-07-06T00:31:40.478239Z"
    },
    "trusted": true
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "!pip install matplotlib ",
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from PIL import Image\nimport requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport os\n\ndef load_image(image_path_or_url):\n    if os.path.exists(image_path_or_url):\n        # Case 1: Local Image File\n        return Image.open(image_path_or_url)\n    elif image_path_or_url.startswith('http'):\n        # Case 2: Image URL\n        response = requests.get(image_path_or_url)\n        image_data = response.content\n        return Image.open(BytesIO(image_data))\n    else:\n        raise ValueError(\"Unsupported image input. Please provide a valid local file path or image URL.\")\n\n# Example usage:\n# image_path_or_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/cat.png?download=true\"\n# or\nimage_path_or_url = \"/kaggle/input/testing-photos/yuta.jpg\"  # Replace with your local image path\n\nraw_image = load_image(image_path_or_url)\n\n# Now `raw_image` contains the loaded image in PIL format\n# You can use `raw_image` as input to your model or processing pipeline\n\n# Example:\nprompt = \"is this a boy or a girl?\"\n\n# Load and display the image\nraw_image = load_image(image_path_or_url)\nplt.imshow(raw_image)\nplt.axis('off')  # Turn off axis labels\nplt.show()\n\ninputs = processor(prompt, raw_image.convert(\"RGB\"), return_tensors=\"pt\")\noutput = model.generate(**inputs, max_new_tokens=20)\nprint(processor.decode(output[0], skip_special_tokens=True)[len(prompt):])\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T00:47:39.774349Z",
     "iopub.execute_input": "2024-07-06T00:47:39.775154Z",
     "iopub.status.idle": "2024-07-06T00:47:48.853172Z",
     "shell.execute_reply.started": "2024-07-06T00:47:39.775123Z",
     "shell.execute_reply": "2024-07-06T00:47:48.852263Z"
    },
    "trusted": true
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Example usage:\nimage_path_or_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/cat.png?download=true\"\n# or\n# image_path_or_url = \"/kaggle/input/testing-photos/yuta.jpg\"  # Replace with your local image path\n\nraw_image = load_image(image_path_or_url)\n\n# Now `raw_image` contains the loaded image in PIL format\n# You can use `raw_image` as input to your model or processing pipeline\n\n# Example:\nprompt = \"what is cat doing?\"\n\n# Load and display the image\nraw_image = load_image(image_path_or_url)\nplt.imshow(raw_image)\nplt.axis('off')  # Turn off axis labels\nplt.show()\n\ninputs = processor(prompt, raw_image.convert(\"RGB\"), return_tensors=\"pt\")\noutput = model.generate(**inputs, max_new_tokens=20)\nprint(processor.decode(output[0], skip_special_tokens=True)[len(prompt):])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T00:48:54.668958Z",
     "iopub.execute_input": "2024-07-06T00:48:54.669774Z",
     "iopub.status.idle": "2024-07-06T00:49:03.814421Z",
     "shell.execute_reply.started": "2024-07-06T00:48:54.669740Z",
     "shell.execute_reply": "2024-07-06T00:49:03.813355Z"
    },
    "trusted": true
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
