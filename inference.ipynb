{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30733,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "!pip install transformers",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T08:13:57.143218Z",
     "iopub.execute_input": "2024-07-06T08:13:57.143778Z",
     "iopub.status.idle": "2024-07-06T08:14:10.816256Z",
     "shell.execute_reply.started": "2024-07-06T08:13:57.143750Z",
     "shell.execute_reply": "2024-07-06T08:14:10.815344Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "!pip install huggingface",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T08:14:10.818285Z",
     "iopub.execute_input": "2024-07-06T08:14:10.819006Z",
     "iopub.status.idle": "2024-07-06T08:14:23.456016Z",
     "shell.execute_reply.started": "2024-07-06T08:14:10.818966Z",
     "shell.execute_reply": "2024-07-06T08:14:23.454392Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "!pip install huggingface_hub",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T08:14:23.457442Z",
     "iopub.execute_input": "2024-07-06T08:14:23.457829Z",
     "iopub.status.idle": "2024-07-06T08:14:35.594320Z",
     "shell.execute_reply.started": "2024-07-06T08:14:23.457787Z",
     "shell.execute_reply": "2024-07-06T08:14:35.593400Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from huggingface_hub import notebook_login\nnotebook_login()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T08:16:03.646848Z",
     "iopub.execute_input": "2024-07-06T08:16:03.647229Z",
     "iopub.status.idle": "2024-07-06T08:16:03.673393Z",
     "shell.execute_reply.started": "2024-07-06T08:16:03.647201Z",
     "shell.execute_reply": "2024-07-06T08:16:03.672544Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "!pip install peft",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T08:14:35.597063Z",
     "iopub.execute_input": "2024-07-06T08:14:35.597433Z",
     "iopub.status.idle": "2024-07-06T08:14:48.426638Z",
     "shell.execute_reply.started": "2024-07-06T08:14:35.597397Z",
     "shell.execute_reply": "2024-07-06T08:14:48.425467Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n\nmodel_id = \"abhishekvidhate/Abhishek-PaliGemma-FT\"\nmodel = PaliGemmaForConditionalGeneration.from_pretrained(model_id)\nprocessor = AutoProcessor.from_pretrained(\"google/paligemma-3b-pt-224\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T08:16:11.712818Z",
     "iopub.execute_input": "2024-07-06T08:16:11.713209Z",
     "iopub.status.idle": "2024-07-06T08:22:44.644708Z",
     "shell.execute_reply.started": "2024-07-06T08:16:11.713179Z",
     "shell.execute_reply": "2024-07-06T08:22:44.643900Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from PIL import Image\nimport requests\n\n\nprompt = \"What is behind the cat?\"\nimage_file = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/cat.png?download=true\"\nraw_image = Image.open(requests.get(image_file, stream=True).raw)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T08:23:40.971446Z",
     "iopub.execute_input": "2024-07-06T08:23:40.972623Z",
     "iopub.status.idle": "2024-07-06T08:23:41.296159Z",
     "shell.execute_reply.started": "2024-07-06T08:23:40.972582Z",
     "shell.execute_reply": "2024-07-06T08:23:41.295143Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "inputs = processor(prompt, raw_image.convert(\"RGB\"), return_tensors=\"pt\")\noutput = model.generate(**inputs, max_new_tokens=20)\n\nprint(processor.decode(output[0], skip_special_tokens=True)[len(prompt):])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T08:23:53.990967Z",
     "iopub.execute_input": "2024-07-06T08:23:53.992108Z",
     "iopub.status.idle": "2024-07-06T08:24:02.912749Z",
     "shell.execute_reply.started": "2024-07-06T08:23:53.992073Z",
     "shell.execute_reply": "2024-07-06T08:24:02.911764Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from PIL import Image\nimport requests\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nimport os\n\ndef load_image(image_path_or_url):\n    if os.path.exists(image_path_or_url):\n        # Case 1: Local Image File\n        return Image.open(image_path_or_url)\n    elif image_path_or_url.startswith('http'):\n        # Case 2: Image URL\n        response = requests.get(image_path_or_url)\n        image_data = response.content\n        return Image.open(BytesIO(image_data))\n    else:\n        raise ValueError(\"Unsupported image input. Please provide a valid local file path or image URL.\")\n\n# Example usage:\nimage_path_or_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/cat.png?download=true\"\n# or\n# image_path_or_url = \"/kaggle/input/testing-photos/yuta.jpg\"  # Replace with your local image path\n\nraw_image = load_image(image_path_or_url)\n\n# Now `raw_image` contains the loaded image in PIL format\n# You can use `raw_image` as input to your model or processing pipeline\n\n# Example:\nprompt = \"what is this?\"\n\n# Load and display the image\nraw_image = load_image(image_path_or_url)\nplt.imshow(raw_image)\nplt.axis('off')  # Turn off axis labels\nplt.show()\n\ninputs = processor(prompt, raw_image.convert(\"RGB\"), return_tensors=\"pt\")\noutput = model.generate(**inputs, max_new_tokens=20)\nprint(processor.decode(output[0], skip_special_tokens=True)[len(prompt):])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-06T08:24:08.630064Z",
     "iopub.execute_input": "2024-07-06T08:24:08.630438Z",
     "iopub.status.idle": "2024-07-06T08:24:18.688279Z",
     "shell.execute_reply.started": "2024-07-06T08:24:08.630408Z",
     "shell.execute_reply": "2024-07-06T08:24:18.687415Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
